import torch
from PIL import Image, ImageDraw
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional
from matplotlib.colors import Normalize
import os
import argparse
import yaml
import sys
from matplotlib.colors import Normalize

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from tester.qwen3vl_visionselector_tester import Qwen3VLVisionSelectorTester


def align_size_to_patch(image: Image.Image, patch_size: int = 16) -> Tuple[int, int]:
    """
    å°†å›¾åƒè°ƒæ•´åˆ°patch_sizeçš„å€æ•°å¤§å°ï¼Œè·å¾—æ–°çš„å›¾åƒå¤§å°
    """
    width, height = image.size
    new_width = round(width / patch_size) * patch_size
    new_height = round(height / patch_size) * patch_size
    if new_width == width and new_height == height:
        return width, height
    return new_width, new_height


def draw_original_image(
    image: Image.Image,
    ax: Optional[plt.Axes] = None,
    save_path: Optional[str] = None,
) -> Image.Image:
    img_copy = image.copy()
    if ax is not None:
        ax.imshow(img_copy)
        ax.axis("off")
        ax.set_title("Original Image")
    if save_path:
        img_copy.save(save_path)
    return img_copy


def draw_bbox_and_pred(
    image: Image.Image,
    bbox: List[float],
    pred: List[float],
    ax: Optional[plt.Axes] = None,
    save_path: Optional[str] = None,
) -> Image.Image:
    img_copy = image.copy()
    W, H = img_copy.size
    draw = ImageDraw.Draw(img_copy)

    x1, y1, x2, y2 = bbox
    if 0 <= x1 <= 1 and 0 <= y1 <= 1 and 0 <= x2 <= 1 and 0 <= y2 <= 1:
        x1, y1 = x1 * W, y1 * H
        x2, y2 = x2 * W, y2 * H
    draw.rectangle([x1, y1, x2, y2], outline="blue", width=4)

    px, py = pred
    if 0 <= px <= 1 and 0 <= py <= 1:
        px, py = px * W, py * H
    r = 14
    draw.ellipse([px - r, py - r, px + r, py + r], fill="red", outline="red")

    if ax is not None:
        ax.imshow(img_copy)
        ax.axis("off")
        ax.set_title("BBox and Prediction")
    if save_path:
        img_copy.save(save_path)
    return img_copy


def draw_selected_tokens(
    image: Image.Image,
    selected_indices: List[int],
    patch_size: int,
    ax: Optional[plt.Axes] = None,
    save_path: Optional[str] = None,
) -> Image.Image:
    img_copy = image.copy().convert("RGBA")
    W, H = img_copy.size
    num_patches_h = H // patch_size
    num_patches_w = W // patch_size
    total_tokens = num_patches_h * num_patches_w

    overlay = Image.new("RGBA", img_copy.size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(overlay)
    selected_set = set(selected_indices)

    for idx in range(total_tokens):
        if idx not in selected_set:
            row = idx // num_patches_w
            col = idx % num_patches_w
            x1, y1 = col * patch_size, row * patch_size
            x2, y2 = (col + 1) * patch_size, (row + 1) * patch_size
            draw.rectangle([x1, y1, x2, y2], fill=(128, 128, 128, 255))

    img_copy = Image.alpha_composite(img_copy, overlay)

    if ax is not None:
        ax.imshow(img_copy)
        ax.axis("off")
        ax.set_title("Selected Tokens")
    if save_path:
        img_copy.save(save_path)
    return img_copy.convert("RGB")


def draw_token_heatmap(
    image: Image.Image,
    token_scores: torch.Tensor,
    patch_size: int,
    ax: Optional[plt.Axes] = None,
    save_path: Optional[str] = None,
) -> Image.Image:
    img_copy = image.copy()
    W, H = img_copy.size
    num_patches_h = H // patch_size
    num_patches_w = W // patch_size

    scores = token_scores.float().cpu().numpy()
    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
    heatmap = scores.reshape(num_patches_h, num_patches_w)
    heatmap = np.repeat(np.repeat(heatmap, patch_size, 0), patch_size, 1)

    # ğŸ‘‰ ç»Ÿä¸€é€»è¾‘ï¼šæ²¡æœ‰ ax å°±è‡ªå·±å»º
    created_ax = False
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(6, 6))
        created_ax = True
    else:
        fig = ax.figure

    ax.imshow(img_copy, alpha=0.4)
    im = ax.imshow(
        heatmap,
        cmap="jet",
        alpha=0.6,
        extent=(0, W, H, 0),
    )
    ax.axis("off")
    ax.set_title("Token Importance Heatmap")

    # â­ æ°¸è¿œåŠ  colorbar
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.02)
    cbar.set_label("Token Importance Score")

    if save_path:
        fig.savefig(save_path, bbox_inches="tight", dpi=300)

    if created_ax:
        plt.close(fig)

    return img_copy


def visualize_tokens(
    image: Image.Image,
    token_scores: torch.Tensor,
    bbox,
    pred,
    save_path,
    selected_indices: Optional[List[int]] = None,
    patch_size: int = 16,
    show: bool = True,
    mode: str = "subplot",
):
    """
    å¯è§†åŒ–åŸå›¾ã€bbox/predã€é€‰ä¸­tokenså’Œtokençƒ­åŠ›å›¾
    """
    # è°ƒæ•´å›¾åƒå¤§å°ä¸ºpatchçš„å€æ•°
    width, height = align_size_to_patch(image, patch_size)
    print(f"è°ƒæ•´åçš„å›¾åƒå¤§å°: {width}x{height}")
    # è®¡ç®—æ€»tokenæ•°é‡
    num_patches_h = height // patch_size
    num_patches_w = width // patch_size
    total_tokens = num_patches_h * num_patches_w
    print(f"æ€»tokenæ•°é‡: {total_tokens}")
    print(f"é€‰æ‹©æ¯”ä¾‹: {len(selected_indices) / total_tokens * 100:.2f}%")

    image = image.resize((width, height)).convert("RGBA")

    fig, axes = plt.subplots(1, 4, figsize=(24, 6))

    # 1. åŸå§‹å›¾åƒ
    draw_original_image(image, ax=axes[0], save_path=os.path.join(save_path, "original.png") if mode == "sep" else None)
    draw_bbox_and_pred(
        image, bbox, pred, ax=axes[1], save_path=os.path.join(save_path, "bbox_pred.png") if mode == "sep" else None
    )

    draw_selected_tokens(
        image,
        selected_indices,
        patch_size,
        ax=axes[2],
        save_path=os.path.join(save_path, "selected_tokens.png") if mode == "sep" else None,
    )

    # 4. çƒ­åŠ›å›¾
    draw_token_heatmap(
        image,
        token_scores,
        patch_size,
        ax=axes[3],
        save_path=os.path.join(save_path, "heatmap.png") if mode == "sep" else None,
    )
    plt.tight_layout()
    if save_path:
        plt.savefig(f"{save_path}.png", bbox_inches="tight", dpi=300)
    if show:
        plt.show()


def visualize_visionselector_tokens(
    tester: Qwen3VLVisionSelectorTester,
    save_path: str,
    sample: dict,
    show: bool = True,
    mode: str = "subplot",
):
    """
    å¯è§†åŒ–Qwen3VLVisionSelectorçš„visual tokené€‰æ‹©

    Args:
        tester: Qwen3VLVisionSelectorTesterå®ä¾‹
        image: è¾“å…¥å›¾åƒ
        instruction: æŒ‡ä»¤æ–‡æœ¬
        save_path: ä¿å­˜è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
        show: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
        sample: åŒ…å«bboxå’Œpredçš„æ ·æœ¬å­—å…¸ï¼ˆå¯é€‰ï¼‰
    """
    # è·å–æ¨¡å‹çš„visualæ¨¡å—
    img_path = sample["img_path"]
    image = Image.open(img_path).convert("RGB")
    instruction = sample["text"]
    visual_model = tester.model.model.visual

    # è·å–patch_size
    patch_size = getattr(visual_model, "patch_size", 16)
    spatial_merge_size = getattr(visual_model, "spatial_merge_size", 2)
    token_patch_size = patch_size * spatial_merge_size

    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆç‚¹å‡»åæ ‡ï¼ˆè¿™ä¼šè§¦å‘visual tokené€‰æ‹©ï¼‰
    coordinates, response = tester.generate_click_coordinate(instruction, image)

    print(f"\nç”Ÿæˆçš„å“åº”: {response}")
    print(f"ç‚¹å‡»åæ ‡: {coordinates}")

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„tokené€‰æ‹©ä¿¡æ¯
    if hasattr(visual_model, "last_selected_indices"):
        selected_indices = visual_model.last_selected_indices.cpu().tolist()
        print(f"\né€‰ä¸­çš„tokenæ•°é‡: {len(selected_indices)}")

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„tokenåˆ†æ•°
    if hasattr(visual_model, "learned_scores"):
        token_scores = visual_model.learned_scores

        print(f"\nTokenåˆ†æ•°å½¢çŠ¶: {token_scores.shape}")

        # å¯è§†åŒ–tokenåˆ†æ•°çƒ­åŠ›å›¾
        print("æ­£åœ¨å¯è§†åŒ–tokenåˆ†æ•°çƒ­åŠ›å›¾...")
        visualize_tokens(
            image=image,
            token_scores=token_scores,
            selected_indices=selected_indices if hasattr(visual_model, "last_selected_indices") else None,
            patch_size=token_patch_size,
            save_path=f"{save_path}" if save_path else None,
            show=show,
            bbox=sample["bbox"],
            pred=coordinates,
            mode=mode,
        )

    return coordinates, response


def main():
    parser = argparse.ArgumentParser(description="å¯è§†åŒ–Qwen3VLVisionSelectorçš„visual token")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--image_path", type=str, required=True, help="å›¾åƒè·¯å¾„")
    parser.add_argument("--instruction", type=str, default="Click on the center of the screen", help="æŒ‡ä»¤æ–‡æœ¬")
    parser.add_argument("--output", type=str, default="./output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--budgets", type=float, default=0.5, help="token budgetæ¯”ä¾‹")

    args = parser.parse_args()

    os.makedirs(args.output, exist_ok=True)

    # åŠ è½½æ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {args.model_path}")
    tester = Qwen3VLVisionSelectorTester(args.model_path, budgets=args.budgets)
    print("æ¨¡å‹åŠ è½½å®Œæˆ")

    # ç”Ÿæˆä¿å­˜è·¯å¾„
    image_name = os.path.splitext(os.path.basename(args.image_path))[0]
    save_path = os.path.join(args.output, f"{image_name}_visualize")
    sample = {
        "img_path": args.image_path,
        "text": args.instruction,
        "bbox": [0.64, 0.10, 0.92, 0.18],
    }
    # å¯è§†åŒ–
    print("\nå¼€å§‹å¯è§†åŒ–...")
    print(f"æŒ‡ä»¤: {args.instruction}")
    coordinates, response = visualize_visionselector_tokens(
        tester=tester,
        save_path=save_path,
        show=False,
        sample=sample,
    )

    print("\nå¯è§†åŒ–å®Œæˆï¼")
    print("è¾“å‡ºæ–‡ä»¶:")
    # print(f"- {save_path}_selected_tokens.png: æ˜¾ç¤ºé€‰æ‹©çš„tokenåŒºåŸŸ")
    print(f"- {save_path}.png: æ˜¾ç¤ºtokenåˆ†æ•°çƒ­åŠ›å›¾")


if __name__ == "__main__":
    main()
    # ç¤ºä¾‹ç”¨æ³•
    # import sys
    # from PIL import Image
    # import torch

    # if len(sys.argv) < 2:
    #     print("Usage: python draw_token.py <image_path> [selected_indices]")
    #     sys.exit(1)

    # # åŠ è½½å›¾åƒ
    # image_path = sys.argv[1]
    # image = Image.open(image_path)

    # # è·å–å›¾åƒçš„å®é™…å¤§å°
    # original_width, original_height = image.size
    # print(f"åŸå§‹å›¾åƒå¤§å°: {original_width}x{original_height}")

    # # ä½¿ç”¨é»˜è®¤çš„patch_size 16
    # patch_size = 16
    # # è®¡ç®—è°ƒæ•´åçš„å›¾åƒå¤§å°ï¼ˆå‘ä¸Šå–æ•´åˆ°patch_sizeçš„å€æ•°ï¼‰
    # adjusted_width = ((original_width + patch_size - 1) // patch_size) * patch_size
    # adjusted_height = ((original_height + patch_size - 1) // patch_size) * patch_size
    # print(f"è°ƒæ•´åçš„å›¾åƒå¤§å° (patch_size={patch_size}çš„å€æ•°): {adjusted_width}x{adjusted_height}")

    # # ç¤ºä¾‹tokenç´¢å¼•ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”ä»æ¨¡å‹è·å–ï¼‰
    # if len(sys.argv) > 2:
    #     selected_indices = list(map(int, sys.argv[2].split(",")))
    # else:
    #     # éšæœºé€‰æ‹©ä¸€åŠçš„tokenä½œä¸ºç¤ºä¾‹
    #     total_tokens = (adjusted_height // patch_size) * (adjusted_width // patch_size)
    #     num_selected = total_tokens // 2  # é€‰æ‹©ä¸€åŠçš„token
    #     selected_indices = np.random.choice(total_tokens, num_selected, replace=False).tolist()
    #     selected_indices.sort()  # ä¿æŒç´¢å¼•é¡ºåº
    #     print(f"éšæœºé€‰æ‹©çš„tokenæ•°é‡: {len(selected_indices)} (æ€»tokenæ•°é‡: {total_tokens})")
    #     print(f"é€‰æ‹©çš„tokenç´¢å¼•: {selected_indices[:10]}...")

    # # ç¤ºä¾‹tokenåˆ†æ•°ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”ä»æ¨¡å‹è·å–ï¼‰
    # total_tokens = (adjusted_height // patch_size) * (adjusted_width // patch_size)
    # token_scores = torch.randn(total_tokens)
    # token_scores = torch.softmax(token_scores, dim=0)

    # # å¯è§†åŒ–tokenåˆ†æ•°çƒ­åŠ›å›¾
    # print("\n--- å¯è§†åŒ–tokenåˆ†æ•°çƒ­åŠ›å›¾ ---")
    # visualize_token_scores(
    #     image=image,
    #     token_scores=token_scores,
    #     selected_indices=selected_indices,
    #     patch_size=patch_size,
    #     save_path="token_heatmap.png",
    # )

    # print("\nå¯è§†åŒ–å®Œæˆï¼")
    # print("è¾“å‡ºæ–‡ä»¶:")
    # print("- selected_tokens.png: æ˜¾ç¤ºé€‰æ‹©çš„tokenåŒºåŸŸ")
    # print("- token_heatmap.png: æ˜¾ç¤ºtokenåˆ†æ•°çƒ­åŠ›å›¾")
